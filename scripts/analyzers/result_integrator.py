#!/usr/bin/env python3
"""
ç»“æœæ•´åˆå™¨

åŠŸèƒ½ï¼š
- æ•´åˆåŸºç¡€ç»Ÿè®¡åˆ†æå’ŒAIåˆ†æç»“æœ
- ç”Ÿæˆç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š
- è®¡ç®—ç»¼åˆè¯„åˆ†å’Œè¶‹åŠ¿åˆ†æ
- æ ¼å¼åŒ–è¾“å‡ºæ•°æ®
"""

import json
from typing import Dict, List, Any, Optional
from datetime import datetime
from collections import defaultdict


class ResultIntegrator:
    """ç»“æœæ•´åˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»“æœæ•´åˆå™¨"""
        self.integrated_results = {}
    
    def integrate_analysis_results(self, basic_analysis: Dict, ai_analysis: Dict, 
                                 article_metadata: List[Dict]) -> Dict[str, Any]:
        """
        æ•´åˆåˆ†æç»“æœ
        
        Args:
            basic_analysis: åŸºç¡€ç»Ÿè®¡åˆ†æç»“æœ
            ai_analysis: AIåˆ†æç»“æœ
            article_metadata: æ–‡ç« å…ƒæ•°æ®åˆ—è¡¨
            
        Returns:
            æ•´åˆåçš„åˆ†ææŠ¥å‘Š
        """
        print("ğŸ”— æ­£åœ¨æ•´åˆåˆ†æç»“æœ...")
        
        # åˆå§‹åŒ–æ•´åˆç»“æœ
        self.integrated_results = {
            'summary': {},
            'writing_style': {},
            'personality_traits': {},
            'content_analysis': {},
            'time_trends': {},
            'ai_insights': {},
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_articles': len(article_metadata),
                'analysis_version': '1.0'
            }
        }
        
        # æ•´åˆåŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        self._integrate_basic_summary(basic_analysis, article_metadata)
        
        # æ•´åˆå†™ä½œé£æ ¼åˆ†æ
        self._integrate_writing_style(basic_analysis, ai_analysis)
        
        # æ•´åˆæ€§æ ¼ç‰¹å¾åˆ†æ
        self._integrate_personality_traits(basic_analysis, ai_analysis)
        
        # æ•´åˆå†…å®¹åˆ†æ
        self._integrate_content_analysis(basic_analysis, ai_analysis)
        
        # åˆ†ææ—¶é—´è¶‹åŠ¿
        self._analyze_time_trends(article_metadata, basic_analysis)
        
        # æ•´åˆAIæ´å¯Ÿ
        self._integrate_ai_insights(ai_analysis)
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        self._calculate_comprehensive_scores()
        
        return self.integrated_results
    
    def _integrate_basic_summary(self, basic_analysis: Dict, article_metadata: List[Dict]):
        """æ•´åˆåŸºç¡€ç»Ÿè®¡æ‘˜è¦"""
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_words = sum(article.get('word_count', 0) for article in article_metadata)
        total_chars = sum(article.get('char_count', 0) for article in article_metadata)
        
        # æ—¶é—´è·¨åº¦
        dates = [article.get('publish_date') for article in article_metadata if article.get('publish_date')]
        if dates:
            try:
                start_date = min(dates)
                end_date = max(dates)
                time_span = f"{start_date} - {end_date}"
            except:
                time_span = "æœªçŸ¥"
        else:
            time_span = "æœªçŸ¥"
        
        # ä¸»é¢˜åˆ†å¸ƒ
        topic_distribution = defaultdict(int)
        for article in article_metadata:
            topic = article.get('main_topic', 'other')
            topic_distribution[topic] += 1
        
        self.integrated_results['summary'] = {
            'total_articles': len(article_metadata),
            'total_words': total_words,
            'total_characters': total_chars,
            'time_span': time_span,
            'main_topics': dict(topic_distribution),
            'avg_words_per_article': round(total_words / len(article_metadata), 1) if article_metadata else 0,
            'avg_chars_per_article': round(total_chars / len(article_metadata), 1) if article_metadata else 0
        }
    
    def _integrate_writing_style(self, basic_analysis: Dict, ai_analysis: Dict):
        """æ•´åˆå†™ä½œé£æ ¼åˆ†æ"""
        # åŸºç¡€ç»Ÿè®¡è¯„åˆ†
        style_scores = basic_analysis.get('style_scores', {})
        
        # AIå†™ä½œé£æ ¼åˆ†æ
        ai_writing_style = ai_analysis.get('writing_style', {})
        
        self.integrated_results['writing_style'] = {
            'vocabulary_richness': style_scores.get('vocabulary_richness', 5.0),
            'sentence_complexity': style_scores.get('sentence_complexity', 5.0),
            'emotional_expression': style_scores.get('emotional_expression', 5.0),
            'structure_organization': style_scores.get('structure_organization', 5.0),
            'overall_style_score': style_scores.get('overall_style', 5.0),
            'ai_interpretation': ai_writing_style.get('content', {}).get('text', 'æš‚æ— AIåˆ†æç»“æœ'),
            'detailed_analysis': {
                'vocabulary': basic_analysis.get('vocabulary', {}),
                'sentences': basic_analysis.get('sentences', {}),
                'paragraphs': basic_analysis.get('writing_patterns', {}).get('paragraph_analysis', {})
            }
        }
    
    def _integrate_personality_traits(self, basic_analysis: Dict, ai_analysis: Dict):
        """æ•´åˆæ€§æ ¼ç‰¹å¾åˆ†æ"""
        # ä»AIåˆ†æä¸­æå–Big Fiveè¯„åˆ†
        ai_personality = ai_analysis.get('personality_traits', {})
        
        # å°è¯•æå–è¯„åˆ†ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å€¼
        try:
            personality_scores = self._extract_personality_scores(ai_personality)
        except:
            personality_scores = {
                'openness': 50,
                'conscientiousness': 50,
                'extraversion': 50,
                'agreeableness': 50,
                'neuroticism': 50
            }
        
        # ä¸­æ–‡æ ‡ç­¾æ˜ å°„
        trait_labels = {
            'openness': 'å¼€æ”¾æ€§',
            'conscientiousness': 'å°½è´£æ€§',
            'extraversion': 'å¤–å‘æ€§',
            'agreeableness': 'å®œäººæ€§',
            'neuroticism': 'ç¥ç»è´¨'
        }
        
        # æ„å»ºæ€§æ ¼ç‰¹å¾æŠ¥å‘Š
        personality_report = {}
        for trait, score in personality_scores.items():
            label = trait_labels.get(trait, trait)
            personality_report[trait] = {
                'score': score,
                'label': label,
                'level': self._get_trait_level(score),
                'description': self._get_trait_description(trait, score)
            }
        
        self.integrated_results['personality_traits'] = {
            'big_five_scores': personality_scores,
            'personality_report': personality_report,
            'ai_interpretation': ai_personality.get('content', {}).get('text', 'æš‚æ— AIåˆ†æç»“æœ'),
            'analysis_confidence': 'high' if ai_personality.get('status') == 'success' else 'low'
        }
    
    def _integrate_content_analysis(self, basic_analysis: Dict, ai_analysis: Dict):
        """æ•´åˆå†…å®¹åˆ†æ"""
        # ä¸»é¢˜åˆ†å¸ƒ
        topics = basic_analysis.get('topics', {})
        
        # æƒ…æ„Ÿåˆ†æ
        emotions = basic_analysis.get('emotions', {})
        
        # AIå†…å®¹åå¥½åˆ†æ
        ai_content = ai_analysis.get('content_preferences', {})
        
        self.integrated_results['content_analysis'] = {
            'topic_distribution': topics.get('topic_distribution', {}),
            'main_topics': topics.get('topic_words', {}),
            'keywords': topics.get('keywords', []),
            'emotional_tone': {
                'overall_sentiment': emotions.get('overall_sentiment', 'neutral'),
                'emotion_ratios': emotions.get('emotion_ratios', {}),
                'emotion_counts': emotions.get('emotion_counts', {})
            },
            'ai_content_analysis': ai_content.get('content', {}).get('text', 'æš‚æ— AIåˆ†æç»“æœ'),
            'writing_techniques': basic_analysis.get('writing_patterns', {}).get('writing_techniques', {})
        }
    
    def _analyze_time_trends(self, article_metadata: List[Dict], basic_analysis: Dict):
        """åˆ†ææ—¶é—´è¶‹åŠ¿"""
        # æŒ‰å¹´ä»½åˆ†ç»„åˆ†æ
        yearly_stats = defaultdict(lambda: {
            'article_count': 0,
            'total_words': 0,
            'avg_words': 0,
            'topics': defaultdict(int),
            'sentiment': defaultdict(int)
        })
        
        for article in article_metadata:
            publish_date = article.get('publish_date', '')
            if publish_date:
                try:
                    year = publish_date[:4]  # æå–å¹´ä»½
                    yearly_stats[year]['article_count'] += 1
                    yearly_stats[year]['total_words'] += article.get('word_count', 0)
                    
                    # ç»Ÿè®¡ä¸»é¢˜
                    topic = article.get('main_topic', 'other')
                    yearly_stats[year]['topics'][topic] += 1
                    
                    # ç»Ÿè®¡æƒ…æ„Ÿ
                    sentiment = article.get('overall_sentiment', 'neutral')
                    yearly_stats[year]['sentiment'][sentiment] += 1
                    
                except:
                    continue
        
        # è®¡ç®—å¹´åº¦å¹³å‡å€¼
        for year, stats in yearly_stats.items():
            if stats['article_count'] > 0:
                stats['avg_words'] = round(stats['total_words'] / stats['article_count'], 1)
        
        # è¶‹åŠ¿åˆ†æ
        years = sorted(yearly_stats.keys())
        if len(years) >= 2:
            # è®¡ç®—å˜åŒ–è¶‹åŠ¿
            word_trend = self._calculate_trend(
                [yearly_stats[year]['avg_words'] for year in years]
            )
            topic_trend = self._analyze_topic_trends(yearly_stats)
        else:
            word_trend = 'insufficient_data'
            topic_trend = {}
        
        self.integrated_results['time_trends'] = {
            'yearly_statistics': dict(yearly_stats),
            'word_count_trend': word_trend,
            'topic_evolution': topic_trend,
            'analysis_period': f"{min(years)} - {max(years)}" if years else "æœªçŸ¥"
        }
    
    def _integrate_ai_insights(self, ai_analysis: Dict):
        """æ•´åˆAIæ´å¯Ÿ"""
        insights = {}
        
        # æå–å„ç»´åº¦çš„AIåˆ†æç»“æœ
        for analysis_type, result in ai_analysis.items():
            if analysis_type != 'analysis_timestamp' and analysis_type != 'analysis_status':
                if result.get('status') == 'success':
                    insights[analysis_type] = {
                        'summary': result.get('content', {}).get('text', 'æš‚æ— åˆ†æç»“æœ'),
                        'details': result.get('content', {}),
                        'confidence': 'high'
                    }
                else:
                    insights[analysis_type] = {
                        'summary': 'åˆ†æå¤±è´¥',
                        'details': {},
                        'confidence': 'low'
                    }
        
        self.integrated_results['ai_insights'] = insights
    
    def _calculate_comprehensive_scores(self):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        # å†™ä½œèƒ½åŠ›ç»¼åˆè¯„åˆ†
        writing_style = self.integrated_results['writing_style']
        writing_score = (
            writing_style['vocabulary_richness'] * 0.25 +
            writing_style['sentence_complexity'] * 0.25 +
            writing_style['emotional_expression'] * 0.25 +
            writing_style['structure_organization'] * 0.25
        )
        
        # å†…å®¹è´¨é‡è¯„åˆ†
        content_analysis = self.integrated_results['content_analysis']
        topic_diversity = len(content_analysis.get('main_topics', {}))
        content_score = min(10, topic_diversity * 2 + 5)  # ä¸»é¢˜å¤šæ ·æ€§ + åŸºç¡€åˆ†
        
        # ä¸ªæ€§ç‰¹å¾å¹³è¡¡æ€§è¯„åˆ†
        personality = self.integrated_results['personality_traits']
        big_five_scores = personality.get('big_five_scores', {})
        if big_five_scores:
            # è®¡ç®—å„ç»´åº¦çš„å¹³è¡¡æ€§ï¼ˆè¶Šæ¥è¿‘50åˆ†è¶Šå¹³è¡¡ï¼‰
            balance_score = 10 - sum(abs(score - 50) for score in big_five_scores.values()) / 50
            balance_score = max(0, min(10, balance_score))
        else:
            balance_score = 5.0
        
        # æ€»ä½“è¯„åˆ†
        overall_score = (writing_score * 0.4 + content_score * 0.3 + balance_score * 0.3)
        
        self.integrated_results['comprehensive_scores'] = {
            'writing_ability': round(writing_score, 1),
            'content_quality': round(content_score, 1),
            'personality_balance': round(balance_score, 1),
            'overall_score': round(overall_score, 1),
            'score_interpretation': self._interpret_overall_score(overall_score)
        }
    
    def _extract_personality_scores(self, personality_analysis: Dict) -> Dict[str, int]:
        """ä»AIåˆ†æä¸­æå–æ€§æ ¼è¯„åˆ†"""
        scores = {
            'openness': 50,
            'conscientiousness': 50,
            'extraversion': 50,
            'agreeableness': 50,
            'neuroticism': 50
        }
        
        try:
            content = personality_analysis.get('content', {})
            if isinstance(content, dict):
                for trait in scores.keys():
                    # æŸ¥æ‰¾åŒ…å«è¯„åˆ†çš„å­—æ®µ
                    for key, value in content.items():
                        if trait in key.lower() and isinstance(value, (int, float)):
                            scores[trait] = min(100, max(0, int(value)))
                        elif isinstance(value, str) and trait in value.lower():
                            # å°è¯•ä»æ–‡æœ¬ä¸­æå–æ•°å­—
                            import re
                            numbers = re.findall(r'\d+', value)
                            if numbers:
                                scores[trait] = min(100, max(0, int(numbers[0])))
        except:
            pass
        
        return scores
    
    def _get_trait_level(self, score: int) -> str:
        """è·å–ç‰¹è´¨æ°´å¹³æè¿°"""
        if score >= 80:
            return 'å¾ˆé«˜'
        elif score >= 60:
            return 'è¾ƒé«˜'
        elif score >= 40:
            return 'ä¸­ç­‰'
        elif score >= 20:
            return 'è¾ƒä½'
        else:
            return 'å¾ˆä½'
    
    def _get_trait_description(self, trait: str, score: int) -> str:
        """è·å–ç‰¹è´¨æè¿°"""
        descriptions = {
            'openness': {
                'high': 'å¯¹æ–°äº‹ç‰©å……æ»¡å¥½å¥‡ï¼Œæ€ç»´å¼€æ”¾ï¼Œå¯Œæœ‰æƒ³è±¡åŠ›',
                'medium': 'å¯¹æ–°äº‹ç‰©æœ‰ä¸€å®šæ¥å—åº¦ï¼Œæ€ç»´ç›¸å¯¹å¼€æ”¾',
                'low': 'åå¥½ç†Ÿæ‚‰çš„äº‹ç‰©ï¼Œæ€ç»´ç›¸å¯¹ä¿å®ˆ'
            },
            'conscientiousness': {
                'high': 'åšäº‹è®¤çœŸè´Ÿè´£ï¼Œæœ‰ç»„ç»‡æ€§ï¼Œç›®æ ‡å¯¼å‘æ˜ç¡®',
                'medium': 'åšäº‹æ¯”è¾ƒè®¤çœŸï¼Œæœ‰ä¸€å®šçš„ç»„ç»‡æ€§',
                'low': 'åšäº‹ç›¸å¯¹éšæ„ï¼Œç»„ç»‡æ€§æœ‰å¾…æé«˜'
            },
            'extraversion': {
                'high': 'æ€§æ ¼å¤–å‘ï¼Œå–„äºè¡¨è¾¾ï¼Œç¤¾äº¤æ´»è·ƒ',
                'medium': 'æ€§æ ¼é€‚ä¸­ï¼Œè¡¨è¾¾å’Œç¤¾äº¤èƒ½åŠ›ä¸€èˆ¬',
                'low': 'æ€§æ ¼å†…å‘ï¼Œè¡¨è¾¾å’Œç¤¾äº¤ç›¸å¯¹ä¿å®ˆ'
            },
            'agreeableness': {
                'high': 'ä¸ºäººå‹å–„ï¼Œå–„äºåˆä½œï¼Œå¯Œæœ‰åŒç†å¿ƒ',
                'medium': 'ä¸ºäººæ¯”è¾ƒå‹å–„ï¼Œåˆä½œæ€§ä¸€èˆ¬',
                'low': 'ä¸ºäººç›¸å¯¹ç›´æ¥ï¼Œåˆä½œæ€§æœ‰å¾…æé«˜'
            },
            'neuroticism': {
                'high': 'æƒ…ç»ªæ³¢åŠ¨è¾ƒå¤§ï¼Œå®¹æ˜“æ„Ÿåˆ°å‹åŠ›å’Œç„¦è™‘',
                'medium': 'æƒ…ç»ªç›¸å¯¹ç¨³å®šï¼Œå¶å°”ä¼šæœ‰æ³¢åŠ¨',
                'low': 'æƒ…ç»ªç¨³å®šï¼ŒæŠ—å‹èƒ½åŠ›å¼º'
            }
        }
        
        if score >= 60:
            level = 'high'
        elif score >= 40:
            level = 'medium'
        else:
            level = 'low'
        
        return descriptions.get(trait, {}).get(level, 'æš‚æ— æè¿°')
    
    def _calculate_trend(self, values: List[float]) -> str:
        """è®¡ç®—è¶‹åŠ¿"""
        if len(values) < 2:
            return 'insufficient_data'
        
        # è®¡ç®—å˜åŒ–ç‡
        changes = []
        for i in range(1, len(values)):
            if values[i-1] != 0:
                change = (values[i] - values[i-1]) / values[i-1]
                changes.append(change)
        
        if not changes:
            return 'no_change'
        
        avg_change = sum(changes) / len(changes)
        
        if avg_change > 0.1:
            return 'increasing'
        elif avg_change < -0.1:
            return 'decreasing'
        else:
            return 'stable'
    
    def _analyze_topic_trends(self, yearly_stats: Dict) -> Dict:
        """åˆ†æä¸»é¢˜æ¼”å˜è¶‹åŠ¿"""
        topic_trends = {}
        
        # è·å–æ‰€æœ‰ä¸»é¢˜
        all_topics = set()
        for year_stats in yearly_stats.values():
            all_topics.update(year_stats['topics'].keys())
        
        # åˆ†ææ¯ä¸ªä¸»é¢˜çš„è¶‹åŠ¿
        for topic in all_topics:
            topic_counts = []
            years = sorted(yearly_stats.keys())
            
            for year in years:
                topic_counts.append(yearly_stats[year]['topics'].get(topic, 0))
            
            trend = self._calculate_trend(topic_counts)
            topic_trends[topic] = {
                'trend': trend,
                'yearly_counts': dict(zip(years, topic_counts))
            }
        
        return topic_trends
    
    def _interpret_overall_score(self, score: float) -> str:
        """è§£é‡Šæ€»ä½“è¯„åˆ†"""
        if score >= 8.5:
            return 'ä¼˜ç§€ - æ‚¨çš„åšå®¢å†™ä½œæ°´å¹³å¾ˆé«˜ï¼Œå†…å®¹è´¨é‡ä¼˜ç§€ï¼Œä¸ªæ€§ç‰¹å¾é²œæ˜'
        elif score >= 7.0:
            return 'è‰¯å¥½ - æ‚¨çš„åšå®¢å†™ä½œæ°´å¹³è‰¯å¥½ï¼Œå†…å®¹è´¨é‡è¾ƒé«˜ï¼Œä¸ªæ€§ç‰¹å¾æ˜æ˜¾'
        elif score >= 5.5:
            return 'ä¸­ç­‰ - æ‚¨çš„åšå®¢å†™ä½œæ°´å¹³ä¸­ç­‰ï¼Œå†…å®¹è´¨é‡ä¸€èˆ¬ï¼Œä¸ªæ€§ç‰¹å¾é€‚ä¸­'
        elif score >= 4.0:
            return 'å¾…æå‡ - æ‚¨çš„åšå®¢å†™ä½œæ°´å¹³æœ‰å¾…æå‡ï¼Œå†…å®¹è´¨é‡éœ€è¦æ”¹è¿›'
        else:
            return 'éœ€è¦åŠªåŠ› - æ‚¨çš„åšå®¢å†™ä½œæ°´å¹³éœ€è¦æ›´å¤šåŠªåŠ›å’Œç»ƒä¹ '
    
    def export_results(self, output_path: str = None) -> str:
        """
        å¯¼å‡ºåˆ†æç»“æœ
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not output_path:
            output_path = f"scripts/output/blog_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.integrated_results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… åˆ†æç»“æœå·²å¯¼å‡ºåˆ°: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºç»“æœå¤±è´¥: {e}")
            return None

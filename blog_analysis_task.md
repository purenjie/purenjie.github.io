# Context
Filename: blog_analysis_task.md
Created On: 2025-01-27
Created By: AI Assistant
Associated Protocol: RIPER-5 + Multidimensional + Agent Protocol

# Task Description
参考现有的 generate_cover_image.py 脚本，新增一个脚本用于读取 /src/content/blog 下的所有博客文章，然后对于博主的文笔、风格、性格等进行分析，最终生成一个适合在 About 页面展示的 AI 分析报告。

# Project Overview
这是一个基于 Astro 的博客项目，博客文章存储在 src/content/blog 目录下，支持两种格式：
1. 单文件 Markdown 格式（如 2025-04-02-初识MCP.md）
2. 目录格式（如 2025-01-12-2024年总结/index.md）

现有脚本使用火山引擎豆包API进行文本处理和图像生成，新脚本将复用相同的API架构进行文本分析。

---
*The following sections are maintained by the AI during protocol execution*
---

# Analysis (Populated by RESEARCH mode)
## 代码结构分析
- 现有脚本使用火山引擎豆包API（ARK_BASE_URL, TEXT_MODEL）
- 支持读取两种博客文章格式：单文件.md和目录/index.md
- 使用Path库进行文件路径处理，支持中文文件名
- 已有完整的错误处理和日志输出机制

## 博客内容特点
- 文章主要使用中文写作
- 包含年度总结、技术教程、读书笔记、生活感悟等多种类型
- 文章长度差异较大（从48行到328行不等）
- 使用frontmatter格式存储元数据（title, publishDate, tags等）
- 内容风格偏向个人化、情感化表达

## 技术约束
- 需要复用现有的火山引擎API配置（DOUBAO_API_KEY, ARK_BASE_URL, TEXT_MODEL）
- 需要处理中文文本分析的特殊性（分词、情感分析等）
- 需要考虑大量文章的处理性能（分批处理、缓存机制）
- 输出格式需要适合在About页面展示（JSON格式，便于前端渲染）
- 项目使用Python环境，需要确保依赖兼容性

## 分析维度需求
基于用户提供的详细需求，需要分析以下维度：
1. 文笔分析：语言复杂度、修辞手法、情感色彩
2. 风格分析：写作类型、结构特征、内容偏好
3. 性格分析：Big Five人格特质、思维模式
4. 时间趋势：写作风格演变
5. 主题分布：高频关键词和话题标签

## 数据源分析
- 博客文章总数：约30+篇
- 文章格式：Markdown + frontmatter
- 时间跨度：2017-2025年
- 内容类型：技术教程、年度总结、读书笔记、生活感悟
- 语言：主要使用中文

# Proposed Solution (Populated by INNOVATE mode)
## 推荐方案：分层分析方案

采用三层架构设计：
1. **基础统计层**：使用jieba分词、textblob等本地库进行词频、句长、段落结构等基础统计
2. **语义分析层**：使用火山引擎API进行主题提取、情感分析、风格识别
3. **风格解读层**：AI生成个性化的写作风格和性格特征描述

## 方案优势
- **可维护性**：分层设计使得每个模块职责清晰，便于后续优化和扩展
- **性能平衡**：基础统计使用本地计算，减少API调用成本
- **结果稳定性**：结合统计数据和AI解读，结果更加客观可靠
- **扩展性**：未来可以轻松添加新的分析维度或更换AI模型

## 技术选型
- **中文分词**：jieba（支持自定义词典）
- **文本统计**：textblob、collections.Counter
- **AI分析**：火山引擎豆包API（复用现有配置）
- **数据输出**：JSON格式，便于前端渲染
- **缓存机制**：本地文件缓存，支持增量更新

# Implementation Plan (Generated by PLAN mode)

## 实现架构设计

### 核心模块
1. **文章读取模块**：读取所有博客文章，支持单文件和目录格式
2. **基础统计模块**：词频统计、句子分析、段落结构分析
3. **AI分析模块**：调用火山引擎API进行深度分析
4. **结果整合模块**：整合统计数据和AI分析结果
5. **输出模块**：生成JSON格式的分析报告

### 文件结构
```
scripts/
├── blog_analysis.py          # 主脚本
├── analyzers/                # 分析器模块
│   ├── __init__.py
│   ├── basic_analyzer.py     # 基础统计分析器
│   ├── ai_analyzer.py        # AI深度分析器
│   └── result_integrator.py  # 结果整合器
├── utils/                    # 工具函数
│   ├── __init__.py
│   ├── text_processor.py     # 文本预处理
│   └── cache_manager.py      # 缓存管理
└── output/                   # 输出目录
    └── blog_analysis.json    # 分析结果
```

## 详细实现步骤

### 步骤1：环境准备和依赖安装
- 创建新的Python脚本文件
- 安装必要的依赖包（jieba, textblob等）
- 复用现有的火山引擎API配置

### 步骤2：文章读取模块实现
- 实现递归遍历博客目录功能
- 支持单文件.md和目录/index.md两种格式
- 提取文章内容和元数据（标题、日期、标签等）
- 文本预处理（去除frontmatter、HTML标签等）

### 步骤3：基础统计模块实现
- 中文分词和词频统计
- 句子长度和复杂度分析
- 段落结构和文章长度统计
- 情感词汇识别和统计
- 主题关键词提取

### 步骤4：AI分析模块实现
- 设计专门的prompt模板
- 调用火山引擎API进行深度分析
- 分析维度：写作风格、性格特征、思维模式
- 结果解析和格式化

### 步骤5：结果整合和输出
- 整合统计数据和AI分析结果
- 生成结构化的JSON报告
- 支持增量更新和缓存机制
- 提供前端展示建议

## 输出数据结构设计

```json
{
  "summary": {
    "total_articles": 30,
    "total_words": 150000,
    "time_span": "2017-2025",
    "main_topics": ["技术", "生活", "读书", "总结"]
  },
  "writing_style": {
    "vocabulary_richness": 7.5,
    "sentence_complexity": "medium",
    "paragraph_structure": "focused",
    "ai_interpretation": "您的写作风格偏向..."
  },
  "personality_traits": {
    "openness": 85,
    "conscientiousness": 60,
    "extraversion": 70,
    "agreeableness": 90,
    "neuroticism": 30,
    "ai_interpretation": "基于您的写作风格..."
  },
  "content_analysis": {
    "topic_distribution": {...},
    "emotional_tone": {...},
    "writing_patterns": {...}
  },
  "time_trends": {
    "style_evolution": {...},
    "topic_shifts": {...}
  }
}
```

## 实现检查清单

1. 创建项目目录结构和基础文件
2. 实现文章读取和预处理功能
3. 实现基础文本统计功能
4. 实现AI分析调用功能
5. 实现结果整合和输出功能
6. 添加缓存和增量更新机制
7. 测试和优化脚本性能
8. 生成示例分析报告
9. 提供使用说明和前端集成建议

## 实施检查清单

1. 创建 `scripts/analyzers/` 目录和 `__init__.py` 文件
2. 创建 `scripts/utils/` 目录和 `__init__.py` 文件
3. 创建 `scripts/output/` 目录
4. 实现 `text_processor.py` - 文本预处理工具
5. 实现 `basic_analyzer.py` - 基础统计分析器
6. 实现 `ai_analyzer.py` - AI深度分析器
7. 实现 `result_integrator.py` - 结果整合器
8. 实现 `cache_manager.py` - 缓存管理器
9. 实现主脚本 `blog_analysis.py`
10. 创建 `requirements.txt` 依赖文件
11. 测试脚本功能并生成示例报告
12. 编写使用说明文档

# Current Execution Step (Updated by EXECUTE mode when starting a step)
[待填充]

# Task Progress (Appended by EXECUTE mode after each step completion)
[待填充]

# Final Review (Populated by REVIEW mode)
[待填充]
